{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Group 3 Project: Digital Image Enhancement\n",
        "**Topic:** Techniques for Fixing Low Contrast Images\n",
        "**Objective:** Compare and implement methods to make dull images look clearer and more vibrant.\n",
        "\n",
        "---\n",
        "### Project Overview\n",
        "Digital images sometimes come out looking dull or \"flat\" because the lighting was poor. This project shows how we can use math and programming (Python) to fix these images. We will look at three main methods: **Contrast Stretching**, **Histogram Equalization**, and **Color Optimization** using special color spaces. \n",
        "\n",
        "This notebook includes our explanations, the code we wrote, and the final results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Getting Ready\n",
        "Before we start, we need to prepare our tools and the image we want to fix. We want every image to be 512x512 pixels so that our math works the same way every time. We also start by working with \"Grayscale\" (black and white) versions of the images to keep things simple.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# A simple tool to find and prepare our image\n",
        "def prepare_image(directory='.'):\n",
        "    # Try to find a low contrast image first\n",
        "    priority_file = os.path.join('Data', 'low_contrast_image.jpg')\n",
        "    image_path = priority_file if os.path.exists(priority_file) else None\n",
        "    \n",
        "    if not image_path:\n",
        "        # If not found, look for any image\n",
        "        valid_types = ('.jpg', '.jpeg', '.png', '.bmp', '.tif')\n",
        "        for d in ['Data', '.']:\n",
        "            if not os.path.exists(d): continue\n",
        "            for file in os.listdir(d):\n",
        "                if file.lower().endswith(valid_types):\n",
        "                    image_path = os.path.join(d, file)\n",
        "                    break\n",
        "            if image_path: break\n",
        "    \n",
        "    if not image_path:\n",
        "        # If we still find nothing, make a fake image so the code doesn't crash\n",
        "        print(\"Note: No image found. Creating a simple test image.\")\n",
        "        img = np.random.normal(128, 20, (512, 512)).astype(np.uint8)\n",
        "        image_path = \"test_image.jpg\"\n",
        "    else:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None: raise ValueError(\"Could not open the image file!\")\n",
        "        # Convert to Black and White (Grayscale)\n",
        "        if len(img.shape) == 3:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Resize to a standard 512x512 size\n",
        "    ready_img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_AREA)\n",
        "    return ready_img, image_path\n",
        "\n",
        "# Run the setup\n",
        "try:\n",
        "    source_img, source_path = prepare_image()\n",
        "    \n",
        "    # Show the original image and its \"Histogram\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(source_img, cmap='gray', vmin=0, vmax=255)\n",
        "    # Using format() instead of f-strings in generated code to avoid quote/newline issues\n",
        "    plt.title(\"Original Image\\nSource: {}\".format(os.path.basename(source_path)))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    # A Histogram is a chart that shows how many dark vs bright pixels are in an image\n",
        "    plt.hist(source_img.ravel(), 256, range=[0, 256], color='gray', alpha=0.7)\n",
        "    plt.title(\"Luminance Histogram (Pixel Distribution)\")\n",
        "    plt.xlabel(\"Brightness Level (0=Black, 255=White)\")\n",
        "    plt.ylabel(\"Number of Pixels\")\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate some numbers to help us understand the image\n",
        "    stats = {\n",
        "        \"Darkest Pixel\": np.min(source_img),\n",
        "        \"Brightest Pixel\": np.max(source_img),\n",
        "        \"Average Brightness\": np.mean(source_img),\n",
        "        \"Contrast Level (Std Dev)\": np.std(source_img)\n",
        "    }\n",
        "    \n",
        "    print(\"{:<25} | {:<12}\".format('Metric', 'Value'))\n",
        "    print(\"-\" * 40)\n",
        "    for name, value in stats.items():\n",
        "        print(\"{:<25} | {:<12.2f}\".format(name, value))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Oops, something went wrong: {}\".format(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: What is \"Low Contrast\"?\n",
        "\n",
        "### 2.1 Understanding Contrast\n",
        "Contrast is basically the difference between the darkest and lightest parts of a picture. \n",
        "- **Low Contrast:** The image looks dull because most of its pixels have very similar brightness. There are no deep blacks and no bright whites.\n",
        "- **High Contrast:** The image looks sharp because there is a wide range from dark to light.\n",
        "\n",
        "### 2.2 What a Histogram Tells Us\n",
        "A **Histogram** is like a map of the image's brightness.\n",
        "- If all the bars are bunched together in a narrow \"mountain,\" the image has low contrast.\n",
        "- If the mountain is on the left, the image is too dark.\n",
        "- If it's on the right, it's too bright.\n",
        "\n",
        "### 2.3 Looking at our Data\n",
        "In our test image, we can see that:\n",
        "- The darkest pixel is around 10 (not truly black).\n",
        "- The brightest pixel is 199 (not truly white).\n",
        "- This \"bunching\" in the middle is why the image looks flat. We need to spread these pixels out!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Method 1 - Contrast Stretching\n",
        "\n",
        "### 3.1 What is it?\n",
        "Imagine the image's brightness range is a rubber band that has been squashed together. **Contrast Stretching** is when we grab both ends of that band and pull them until they reach 0 (Black) and 255 (White).\n",
        "\n",
        "### 3.2 How it works (The Math)\n",
        "We use a simple formula for every pixel:\n",
        "$$ NewPixel = \\frac{OldPixel - Minimum}{Maximum - Minimum} \\times 255 $$\n",
        "\n",
        "This math ensures the darkest pixels become 0 and the brightest become 255, stretching everything else in between. \n",
        "\n",
        "### 3.3 Why use it?\n",
        "It's very fast and simple. It makes the image look much clearer without changing the \"feeling\" of the picture too much.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python function to stretch the contrast\n",
        "def stretch_contrast(image):\n",
        "    # Convert to float so we can do precise math\n",
        "    f_img = image.astype(float)\n",
        "    \n",
        "    # We use the 2nd and 98th percentile to find the min and max\n",
        "    # This helps ignore \"dots\" of light or dark that might be errors\n",
        "    min_val = np.percentile(f_img, 2)\n",
        "    max_val = np.percentile(f_img, 98)\n",
        "    \n",
        "    if max_val == min_val: return image\n",
        "        \n",
        "    # Apply the stretching formula\n",
        "    result = (f_img - min_val) * (255.0 / (max_val - min_val))\n",
        "    \n",
        "    # Ensure values stay between 0 and 255, then convert back to image format\n",
        "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
        "    return result\n",
        "\n",
        "# Apply the fix and show the result\n",
        "cs_image = stretch_contrast(source_img)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(cs_image, cmap='gray', vmin=0, vmax=255)\n",
        "plt.title(\"After Contrast Stretching\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Notice how the bars are now spread out across the whole chart\n",
        "plt.hist(cs_image.ravel(), 256, range=[0, 256], color='blue', alpha=0.6)\n",
        "plt.title(\"New Histogram (Spread Out)\")\n",
        "plt.xlim([0, 256])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Method 2 - Histogram Equalization\n",
        "\n",
        "### 4.1 What is it?\n",
        "While Stretching just pulls the ends of the rubber band, **Histogram Equalization** tries to flatten the \"mountain\" so that there is an equal amount of every brightness level. This makes the picture look much more intense.\n",
        "\n",
        "### 4.2 Key Terms\n",
        "- **PDF (Probability Distribution):** How likely is a certain brightness value?\n",
        "- **CDF (Cumulative Distribution):** Adding up the probabilities. This \"CDF\" becomes our map to change the pixels.\n",
        "\n",
        "### 4.3 CLAHE (A Smarter Way)\n",
        "Sometimes regular Equalization makes a picture look \"fake\" or too noisy. **CLAHE** (Contrast Limited Adaptive Histogram Equalization) is a smarter version. It breaks the image into small squares and fixes them one by one, making sure it doesn't add too much noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation of the two equalization methods\n",
        "def equalize_histogram(image):\n",
        "    # Calculate the distribution and the cumulative map (CDF)\n",
        "    hist, _ = np.histogram(image.flatten(), 256, range=[0, 256])\n",
        "    cdf = hist.cumsum()\n",
        "    \n",
        "    # Normalize the map to 0-255\n",
        "    cdf_m = np.ma.masked_equal(cdf, 0)\n",
        "    if (cdf_m.max() - cdf_m.min()) == 0: return image\n",
        "    cdf_norm = (cdf_m - cdf_m.min()) * 255 / (cdf_m.max() - cdf_m.min())\n",
        "    map_table = np.ma.filled(cdf_norm, 0).astype('uint8')\n",
        "    \n",
        "    return map_table[image]\n",
        "\n",
        "def apply_clahe(image):\n",
        "    # Using the OpenCV built-in tool for CLAHE\n",
        "    engine = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return engine.apply(image)\n",
        "\n",
        "# Run both and compare\n",
        "he_image = equalize_histogram(source_img)\n",
        "clahe_image = apply_clahe(source_img)\n",
        "\n",
        "plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(he_image, cmap='gray', vmin=0, vmax=255)\n",
        "plt.title(\"Method: Global Equalization\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(clahe_image, cmap='gray', vmin=0, vmax=255)\n",
        "plt.title(\"Method: CLAHE (Adaptive)\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.hist(he_image.ravel(), 256, range=[0, 256], color='green', alpha=0.5, label='Global')\n",
        "plt.hist(clahe_image.ravel(), 256, range=[0, 256], color='red', alpha=0.5, label='CLAHE')\n",
        "plt.title(\"Histogram Comparison\")\n",
        "plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Helping Color Images\n",
        "\n",
        "Enhancing color images is tricky. If we just fix the Red, Green, and Blue separately, the colors will change and look weird.\n",
        "\n",
        "### 5.1 The LAB Color Space\n",
        "To solve this, we use a different way to look at color called **LAB**:\n",
        "- **L (Lightness):** Only the brightness.\n",
        "- **A & B:** Only the color info.\n",
        "\n",
        "By fixing **only the L channel** (the brightness), we can make the image clearer while keeping the colors exactly as they should be!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool to fix a color image safely\n",
        "def fix_color_image(path):\n",
        "    src = cv2.imread(path)\n",
        "    if src is None: return None\n",
        "    \n",
        "    # Change from standard BGR to LAB\n",
        "    lab = cv2.cvtColor(src, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    \n",
        "    # Fix ONLY the L (brightness) channel using CLAHE\n",
        "    engine = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    l_new = engine.apply(l)\n",
        "    \n",
        "    # Put the pieces back together and convert back to normal color\n",
        "    merged = cv2.merge((l_new, a, b))\n",
        "    fixed = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "    return cv2.cvtColor(fixed, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Show the results for the color version\n",
        "color_result = fix_color_image(source_path)\n",
        "\n",
        "if color_result is not None:\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(cv2.imread(source_path), cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Color Image\"); plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(color_result)\n",
        "    plt.title(\"Enhanced Color Image (LAB Method)\"); plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Final Comparison\n",
        "\n",
        "How do we know which method is better? We look at two things:\n",
        "1.  **Contrast Score (Std Dev):** A higher number means a wider range from light to dark.\n",
        "2.  **Detail Score (Entropy):** A higher number means more visible patterns and \"information\" in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_detail_score(img):\n",
        "    hist, _ = np.histogram(img, 256, range=[0, 256])\n",
        "    p = hist / hist.sum()\n",
        "    p = p[p > 0]\n",
        "    return -np.sum(p * np.log2(p))\n",
        "\n",
        "methods = {\n",
        "    \"Original\": source_img,\n",
        "    \"Stretched\": cs_image,\n",
        "    \"Equalized\": he_image,\n",
        "    \"CLAHE\": clahe_image\n",
        "}\n",
        "\n",
        "print(\"{:<25} | {:<15} | {:<15}\".format('Method Used', 'Contrast Score', 'Detail Score'))\n",
        "print(\"-\" * 60)\n",
        "for name, img in methods.items():\n",
        "    contrast = np.std(img)\n",
        "    detail = get_detail_score(img)\n",
        "    print(\"{:<25} | {:<15.2f} | {:<15.4f}\".format(name, contrast, detail))\n",
        "\n",
        "# Final Visual Comparison\n",
        "plt.figure(figsize=(12, 10))\n",
        "list_imgs = [source_img, cs_image, he_image, clahe_image]\n",
        "list_titles = [\"Original\", \"Stretched\", \"Equalized\", \"CLAHE\"]\n",
        "\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.imshow(list_imgs[i], cmap='gray', vmin=0, vmax=255)\n",
        "    plt.title(list_titles[i])\n",
        "    plt.axis('off')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Final Summary\n",
        "After testing all methods, here is what our group found:\n",
        "- **Contrast Stretching** is the simplest and safest way to fix a slightly dull photo.\n",
        "- **Histogram Equalization** is very powerful but can sometimes make an image look \"fake\" by adding too much noise.\n",
        "- **CLAHE** is the best balance for most cases, especially if you use it on the **L channel** of a color image. It reveals hidden details without destroying the original look of the picture.\n",
        "\n",
        "We hope this project clearly shows how simple math can be used to improve the technology we use every day!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}